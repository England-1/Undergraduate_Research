{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:DarkGreen\"> *Precipitation Type Diagnostic Product for Sentinal Stations* </span>\n",
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Notes:</b> FIX NYSM FZRA & FIX SENT PTYPE\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Notes:</b> Latest Version. Needs to run on daes_may21 Kernal. No exterior scripts are need to run notebook, move it where needed.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Datasets Used:**\n",
    "\n",
    "#### **HREF Members Used:**\n",
    "\n",
    "###### *- Advanced Research Weather (HRW WRF-ARW)*\n",
    "###### *- Finite Volume Cubed Sphere (HRW WRF-FV3)*\n",
    "###### *- National Severe Storms Laboratory (HRW WRF-NSSL)*\n",
    "###### *- North American Model (NAM 3km CONUS)*\n",
    "###### *- High Resolution Rapid Refresh (HRRR)*\n",
    "\n",
    "#### **Observations Used:**\n",
    "###### *- New York State Mesonet (NYSM)*\n",
    "###### *- CFI Climate Sentinal Stations (CFI)*\n",
    "###### *- Automated Surface Observing Systems (ASOS)*\n",
    "###### *- Meteorological Phenomena Identification Near the Ground (mPING)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HREF Initialization Time \n",
    "year = 2022\n",
    "month = 2\n",
    "day = 22\n",
    "hour = 12\n",
    "minute = 0\n",
    "\n",
    "# HREF Forecast Hour(s)\n",
    "starthour = 15\n",
    "endhour = 15\n",
    "inc = 1\n",
    "\n",
    "# Selected Intensive Observational Period\n",
    "IOP=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports & File Grabbing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using the following paths to grab NYSM data:\n",
      "/network/rit/lab/minderlab_rit/NYSM/winter_products/20220222.nc\n",
      "/network/rit/lab/minderlab_rit/NYSM/winter_products/20220223.nc\n",
      "/network/rit/lab/minderlab_rit/NYSM/winter_products/20220224.nc\n",
      "\n",
      "We are using the following paths to grab HREF data:\n",
      "/network/rit/lab/minderlab_rit/je845911/data/href/2022/20220222/hiresw_conusarw_2022022212f015.grib2\n",
      "\n",
      "We are using the following paths to grab HREF data:\n",
      "/network/rit/lab/minderlab_rit/je845911/data/href/2022/20220222/hiresw_conusfv3_2022022212f015.grib2\n",
      "\n",
      "We are using the following paths to grab HREF data:\n",
      "/network/rit/lab/minderlab_rit/je845911/data/href/2022/20220222/hiresw_conusnssl_2022022212f015.grib2\n",
      "\n",
      "We are using the following paths to grab HREF data:\n",
      "/network/rit/lab/minderlab_rit/je845911/data/href/2022/20220222/hrrr_ncep_2022022212f015.grib2\n",
      "\n",
      "We are using the following paths to grab HREF data:\n",
      "/network/rit/lab/minderlab_rit/je845911/data/href/2022/20220222/nam_conusnest_2022022212f015.grib2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# core\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import cfgrib\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Collections\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "\n",
    "# netCDF4\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# datetime\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "#cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeat \n",
    "from cartopy import feature as cfeature\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from matplotlib.dates import DateFormatter, AutoDateLocator,HourLocator,DayLocator,MonthLocator\n",
    "\n",
    "# metpy\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "from metpy.plots import StationPlot, USCOUNTIES\n",
    "from metpy.calc import wind_speed, wind_direction, relative_humidity_from_dewpoint, wind_components\n",
    "\n",
    "#Load in field sites\n",
    "sites = pd.read_csv('/network/rit/home/je845911/minlab/je845911/data/nysm/site_locations.txt')\n",
    "\n",
    "#Getting coordinates for mesonet data because 2022 files dont have them\n",
    "fpath_coords = '/network/rit/lab/minderlab_rit/NYSM/standard/netCDF/2019/20190902.nc'\n",
    "\n",
    "# Canadian Sentinal Network Data (02/2022 -> 04/2022)\n",
    "sentinal = '/network/rit/home/je845911/minlab/je845911/data/sentinal/sentinels_metdata.nc'\n",
    "sent_base = '/network/rit/home/je845911/minlab/je845911/data/sentinal/p-type/sentinels_metdata.nc' # Temperature & Accumulated Precipitation\n",
    "sent_ice = '/network/rit/home/je845911/minlab/je845911/data/sentinal/p-type/CFI_Sentinels_icing_detector_data_WINTRE-MIX.nc' # Ice Accumulation\n",
    "sent_snow = '/network/rit/home/je845911/minlab/je845911/data/sentinal/p-type/CFI_Sentinels_Snowdepth.nc' # Snowdepth\n",
    "sent_precip = '/network/rit/home/je845911/minlab/je845911/data/sentinal/p-type/sentinels_hotplates.nc'\n",
    "\n",
    "# Grabbing relevant ASOS CSV\n",
    "if IOP == 4:\n",
    "    df_NY = pd.read_csv('/network/rit/home/je845911/minlab/je845911/data/asos/five_pannel/IOP4_NY_ASOS_PTYPE.csv')\n",
    "    df_VT = pd.read_csv('/network/rit/home/je845911/minlab/je845911/data/asos/five_pannel/IOP4_VT_ASOS_PTYPE.csv')\n",
    "    df_QE = pd.read_csv('/network/rit/home/je845911/minlab/je845911/data/asos/five_pannel/IOP4_QE_ASOS_PTYPE.csv')\n",
    "    df_ON = pd.read_csv('/network/rit/home/je845911/minlab/je845911/data/asos/five_pannel/IOP4_ON_ASOS_PTYPE.csv')\n",
    "    \n",
    "    # Freezing Rain Data\n",
    "    field_dir_17= '/network/rit/lab/minderlab_rit/field_data/WINTRE_MIX_data/FZRA_data_netcdf/v1.0/WINTRE-MIX_NYSM_icing_detector_20220217_5min.nc'\n",
    "    field_dir_18 = '/network/rit/lab/minderlab_rit/field_data/WINTRE_MIX_data/FZRA_data_netcdf/v1.0/WINTRE-MIX_NYSM_icing_detector_20220218_5min.nc'\n",
    "    obs = pd.read_csv('/network/rit/home/je845911/minlab/je845911/data/sounding/iop4/sounding_locations/site-locations.txt')\n",
    "    lats_OBS = obs['lat'].astype(float)\n",
    "    lons_OBS = obs['lon'].astype(float)-obs['lon'].astype(float)-obs['lon'].astype(float)\n",
    "    \n",
    "else:\n",
    "    df_NY = pd.read_csv('/network/rit/home/je845911/minlab/je845911/data/asos/five_pannel/newyork.csv')\n",
    "    df_VT = pd.read_csv('/network/rit/home/je845911/minlab/je845911/data/asos/five_pannel/vermont.csv')\n",
    "    df_QE = pd.read_csv('/network/rit/home/je845911/minlab/je845911/data/asos/five_pannel/quebec.csv')\n",
    "    df_ON = pd.read_csv('/network/rit/home/je845911/minlab/je845911/data/asos/five_pannel/ontario.csv')\n",
    "    \n",
    "    # Freezing Rain Data\n",
    "    field_dir_17= '/network/rit/lab/minderlab_rit/field_data/WINTRE_MIX_data/FZRA_data_netcdf/v1.0/WINTRE-MIX_NYSM_icing_detector_20220222_5min.nc'\n",
    "    field_dir_18 = '/network/rit/lab/minderlab_rit/field_data/WINTRE_MIX_data/FZRA_data_netcdf/v1.0/WINTRE-MIX_NYSM_icing_detector_20220223_5min.nc'\n",
    "    obs = pd.read_csv('/network/rit/home/je845911/minlab/je845911/data/sounding/iop5/sounding_locations/site-locations.txt')\n",
    "    lats_OBS = obs['lat'].astype(float)\n",
    "    lons_OBS = obs['lon'].astype(float)-obs['lon'].astype(float)-obs['lon'].astype(float)\n",
    "\n",
    "# NYSM File Grabbing\n",
    "hour_delta = 0\n",
    "minute_delta = 15\n",
    "year_str = str(year)\n",
    "month_str = str(month).zfill(2)\n",
    "day_str = str(day)\n",
    "hour_str = str(hour).zfill(2)\n",
    "day2_str = str(day+1)\n",
    "day3_str = str(day+2)   \n",
    "base_dir = '/network/rit/lab/minderlab_rit/NYSM'\n",
    "winter_dir = '/winter_products'\n",
    "winter_1 = base_dir + winter_dir + '/' + year_str + month_str + day_str + '.nc'    \n",
    "winter_2 = base_dir + winter_dir + '/' + year_str + month_str + day2_str + '.nc'  \n",
    "winter_3 = base_dir + winter_dir + '/' + year_str + month_str + day3_str + '.nc'    \n",
    "print('We are using the following paths to grab NYSM data:')\n",
    "print(winter_1)\n",
    "print(winter_2)\n",
    "print(winter_3)\n",
    "print()\n",
    "NYSM_ptype = xr.open_mfdataset([winter_1,winter_2,winter_3])\n",
    "ds_coords = xr.open_dataset(fpath_coords)\n",
    "ds_feb_zr = xr.open_mfdataset([field_dir_17,field_dir_18])\n",
    "####################################################################################\n",
    "# HREF File Grabbing\n",
    "\n",
    "href_base_dir = '/network/rit/lab/minderlab_rit/je845911/data/href'\n",
    "yyyymmddhh_str = year_str + month_str + day_str + hour_str\n",
    "yyyymmdd_str = yyyymmddhh_str[0:8]\n",
    "yyyy_str = yyyymmddhh_str[0:4]\n",
    "endhour = endhour +1\n",
    "fhrs = np.arange(starthour,endhour,inc)\n",
    "length = len(fhrs)\n",
    "\n",
    "# ARW\n",
    "arw = []\n",
    "for fhr in fhrs:\n",
    "    arw.append(f'{href_base_dir}/{yyyy_str}/{yyyymmdd_str}/hiresw_conusarw_' + f'{yyyymmddhh_str}f0'+str(fhr).zfill(2)+'.grib2')\n",
    "\n",
    "# FV3\n",
    "fv3 = []\n",
    "for fhr in fhrs:\n",
    "    fv3.append(f'{href_base_dir}/{yyyy_str}/{yyyymmdd_str}/hiresw_conusfv3_' + f'{yyyymmddhh_str}f0'+str(fhr).zfill(2)+'.grib2')\n",
    "\n",
    "# NSSL\n",
    "nssl = []\n",
    "for fhr in fhrs:\n",
    "    nssl.append(f'{href_base_dir}/{yyyy_str}/{yyyymmdd_str}/hiresw_conusnssl_' + f'{yyyymmddhh_str}f0'+str(fhr).zfill(2)+'.grib2')\n",
    "\n",
    "# NCEP\n",
    "ncep = []\n",
    "for fhr in fhrs:\n",
    "    ncep.append(f'{href_base_dir}/{yyyy_str}/{yyyymmdd_str}/hrrr_ncep_' + f'{yyyymmddhh_str}f0'+str(fhr).zfill(2)+'.grib2')\n",
    "\n",
    "# NAM\n",
    "nam = []\n",
    "for fhr in fhrs:\n",
    "    nam.append(f'{href_base_dir}/{yyyy_str}/{yyyymmdd_str}/nam_conusnest_' + f'{yyyymmddhh_str}f0'+str(fhr).zfill(2)+'.grib2')\n",
    "\n",
    "print(\"We are using the following paths to grab HREF data:\")\n",
    "for fpath in arw:\n",
    "    print(fpath)\n",
    "print()\n",
    "print(\"We are using the following paths to grab HREF data:\")\n",
    "for fpath in fv3:\n",
    "    print(fpath)\n",
    "print()\n",
    "print(\"We are using the following paths to grab HREF data:\")\n",
    "for fpath in nssl:\n",
    "    print(fpath)\n",
    "print()\n",
    "print(\"We are using the following paths to grab HREF data:\")\n",
    "for fpath in ncep:\n",
    "    print(fpath)\n",
    "print()\n",
    "print(\"We are using the following paths to grab HREF data:\")\n",
    "for fpath in nam:\n",
    "    print(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P-Type Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making precipitation type variable for ARBO\n",
      "Making precipitation type variable for GAUL\n",
      "Making precipitation type variable for TROI\n",
      "Making precipitation type variable for UQAM\n"
     ]
    }
   ],
   "source": [
    "sent_base = xr.open_dataset(sentinal)\n",
    "sent_base = sent_base.drop(['max_wind_direction','height_above_mean_sea_level','relative_humidity','station_pressure','wind_speed','wind_direction','wind_direction_stddev','max_wind_speed','max_wind_direction'])\n",
    "sent_base = sent_base.to_dataframe()\n",
    "sent_base = sent_base.reset_index(level=1)\n",
    "sent_base = sent_base.rename(columns={\"latitude\":\"lat\",\"longitude\":\"lon\"})\n",
    "\n",
    "sent_ice = xr.open_dataset(sent_ice, drop_variables = 'station')\n",
    "sent_ice = sent_ice.drop(['heater_status','ice','height_above_mean_sea_level'])\n",
    "new_time, empty_time = [], []\n",
    "sentinal_time, mock_time = datetime(2021,11,1,0,0), range(0,217440,1)\n",
    "for i in mock_time:\n",
    "    adj_time = sentinal_time + timedelta(minutes=i)\n",
    "    new_time.append(adj_time)\n",
    "time = np.array(new_time)\n",
    "sent_ice = sent_ice.assign_coords({\"time\":time})\n",
    "sent_ice = sent_ice.to_dataframe()\n",
    "sent_ice = sent_ice.reset_index(level=1)\n",
    "sent_ice['station'] = sent_ice['station'].replace([0], 'GAUL')\n",
    "sent_ice['station'] = sent_ice['station'].replace([1], 'ARBO')\n",
    "sent_ice['station'] = sent_ice['station'].replace([2], 'UQAM')\n",
    "sent_ice['station'] = sent_ice['station'].replace([3], 'TROI')\n",
    "sent_ice.loc[sent_ice['lon'] < 0, 'lon'] = sent_ice['lon'] - sent_ice['lon'] - sent_ice['lon'] # Change Lon values from - to +\n",
    "\n",
    "sent_snow = xr.open_dataset(sent_snow)\n",
    "sent_snow = sent_snow.drop(['height_above_mean_sea_level','swe_cs725'])\n",
    "new_time, empty_time = [], []\n",
    "sentinal_time, mock_time = datetime(2021,11,1,0,0), range(0,216001,1)\n",
    "for i in mock_time:\n",
    "    adj_time = sentinal_time + timedelta(minutes=i)\n",
    "    new_time.append(adj_time)\n",
    "time = np.array(new_time)\n",
    "sent_snow = sent_snow.assign_coords({\"time\":time})\n",
    "sent_snow = sent_snow.to_dataframe()\n",
    "sent_snow = sent_snow.reset_index(level=1)\n",
    "sent_snow = sent_snow.rename(columns={\"latitude\":\"lat\",\"longitude\":\"lon\"})\n",
    "sent_snow.loc[sent_snow['lon'] < 0, 'lon'] = sent_snow['lon'] - sent_snow['lon'] - sent_snow['lon'] # Change Lon values from - to +\n",
    "\n",
    "sent_ap = xr.open_dataset(sent_precip)\n",
    "sent_ap = sent_ap.to_dataframe()\n",
    "sent_ap = sent_ap.rename(columns={\"latitude\":\"lat\",\"longitude\":\"lon\"})\n",
    "sent_ap = sent_ap.drop(columns=['height_above_mean_sea_level','status_k63'])\n",
    "\n",
    "\n",
    "sent_total = pd.merge(sent_ice, sent_base, on=[\"time\",\"lat\",\"lon\"])\n",
    "sent_total = pd.merge(sent_total, sent_snow, on=['time',\"station\"])\n",
    "sent_total = pd.merge(sent_total, sent_ap, on=['time',\"station\"])\n",
    "sent_total = sent_total.drop(columns=['lat_y','lon_y','lat','lon'])\n",
    "sent_total = sent_total.rename(columns={\"lat_x\":\"lat\",\"lon_x\":\"lon\"})\n",
    "sent_total = sent_total.set_index(['time','station'])\n",
    "sent_total.index.names\n",
    "sent_total = sent_total.loc[('2022-02-17 22:00:00'):('2022-02-23 12:00:00')]\n",
    "\n",
    "sent_total['snow_depth_avg_sdms40'] = sent_total['snow_depth_avg_sdms40'].diff(periods = 4)\n",
    "sent_total['snow_depth_sr50a'] = sent_total['snow_depth_sr50a'].diff(periods = 4)\n",
    "\n",
    "sent_total['ice_status'] = sent_total['ice_status'].replace([b'Y'], 1)\n",
    "sent_total['ice_status'] = sent_total['ice_status'].replace([b'N'], 0)\n",
    "sent_total['ice_status'] = sent_total['ice_status'].replace([b'E'], 0)\n",
    "sent_total['ice_status'] = sent_total['ice_status'].replace([b'M'], 0)\n",
    "sent_total['ice_status'] = sent_total['ice_status'].replace([b'Q'], 0)\n",
    "\n",
    "\n",
    "\n",
    "xr = sent_total.to_xarray()\n",
    "xr['ice_status'].astype(int)\n",
    "xr_ice= xr.resample(time='5min').max(dim='time')\n",
    "xr = xr.resample(time='5min').mean(dim='time')\n",
    "\n",
    "for i in xr['station'].values:\n",
    "    print('Making precipitation type variable for ' + i)\n",
    "\n",
    "    # P_TYPE NO PRECIP. CHECK (-1) (0)\n",
    "    a = np.where(xr['precipitation_rate_k63'].sel(station = i) > 0.004,-0.1,-0.5)#0.025\n",
    "\n",
    "    # P-TYPE ICE CHECK (5)\n",
    "    b = np.where((xr['precipitation_rate_k63'].sel(station = i) > 0.025) & (xr['temp_2m'].sel(station = i) <= 0) & (xr_ice['ice_status'].sel(station = i) == 1),1.5,a)\n",
    "\n",
    "    # P-TYPE RAIN CHECK (8)\n",
    "    c = np.where((xr['precipitation_rate_k63'].sel(station = i) > 0.025) & (xr['temp_2m'].sel(station = i) > 0) & (xr_ice['ice_status'].sel(station = i) == 0),7,b)\n",
    "\n",
    "    # P-TYPE SNOW CHECK (1)\n",
    "    d = np.where((xr['precipitation_rate_k63'].sel(station = i) > 0.025) & (xr['temp_2m'].sel(station = i) <= 0) & (xr['snow_depth_sr50a'].sel(station = i) >= .05) & (xr_ice['ice_status'].sel(station = i) == 0),0.5,c)\n",
    "\n",
    "    # P-TPYE SNOW CHECK (1)\n",
    "    e = np.where((xr['precipitation_rate_k63'].sel(station = i) > 0.025) & (xr['temp_2m'].sel(station = i) <= 0) & (xr['snow_depth_avg_sdms40'].sel(station = i) >= .05) & (xr_ice['ice_status'].sel(station = i) == 0),0.5,d)\n",
    "\n",
    "    # P-TYPE Unknown (Leftover)\n",
    "    PTYPE = np.where((e==-1),10.5,e)\n",
    "    \n",
    "#norm_ptype_ext = mpl.colors.BoundaryNorm([-1,  0,    1,   2,     3,   5,     6,     8,     9,     10,   11],ncolors = len(ptype_colors))\n",
    "#ptype_labels = [                           'NP'  'SN',' IP''IP/SN' ZR'' ZR/IP','RA','RA/SN','RA/IP','UP']\n",
    "    \n",
    "    if i == 'ARBO':\n",
    "        PTYPE_ARBO = PTYPE\n",
    "    elif i == 'TROI':\n",
    "        PTYPE_TROI = PTYPE\n",
    "    elif i == 'UQAM':\n",
    "        PTYPE_UQAM = PTYPE\n",
    "    elif i == 'GAUL':\n",
    "        PTYPE_GAUL = PTYPE\n",
    "\n",
    "PTYPE_df = xr['time'].to_dataframe()\n",
    "PTYPE_df['ARBO'] = PTYPE_ARBO\n",
    "PTYPE_df['A_lat'] = 45.430065\n",
    "PTYPE_df['A_lon'] = -73.942156\n",
    "PTYPE_df['GAUL'] = PTYPE_GAUL\n",
    "PTYPE_df['G_lat'] = 45.535021\n",
    "PTYPE_df['G_lon'] = -73.149006\n",
    "PTYPE_df['UQAM'] = PTYPE_UQAM\n",
    "PTYPE_df['U_lat'] = 45.508594\n",
    "PTYPE_df['U_lon'] = -73.568741\n",
    "PTYPE_df['TROI'] = PTYPE_TROI\n",
    "PTYPE_df['T_lat'] = 46.349835\n",
    "PTYPE_df['T_lon'] = -72.581354"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in xr['station'].values:\n",
    "   \n",
    "    # Meteogram and PType Output\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.title('Meteogram for '+i,fontsize = 20)\n",
    "    if i == 'ARBO':\n",
    "        j = PTYPE_ARBO\n",
    "    elif i == 'TROI':\n",
    "        j = PTYPE_TROI\n",
    "    elif i == 'UQAM':\n",
    "        j = PTYPE_UQAM\n",
    "    elif i == 'GAUL':\n",
    "        j = PTYPE_GAUL\n",
    "    # PTYPE Figure\n",
    "    ax1 = fig.add_subplot(5,1,1)\n",
    "    ax1.scatter (xr['time'],j, linewidth = .05, zorder = 6, marker = 7,color = 'black')\n",
    "    ax1.set_ylim(-1,9)\n",
    "    ax1.set_yticks([0,1,2,5,8])\n",
    "    ax1.grid(color='black',linewidth=0.3)    \n",
    "    ax1.set_ylabel ('P-Type Raw', fontsize = 14)\n",
    "    ax1.set_yticklabels(['NP','SN','IP','ZR','RA'])\n",
    "    plt.axvspan('2022-02-23 06:00','2022-02-23 06:00',color = 'k',alpha=1, zorder = 1)\n",
    "\n",
    "\n",
    "    # Snow Depth Figure\n",
    "    ax2 = fig.add_subplot(5,1,2)\n",
    "    ax2.set_ylabel ('Snow Depth (mm)', fontsize = 13)\n",
    "    ax2.grid(color='black',linewidth=0.3)\n",
    "    ax2.plot (xr['time'],xr['snow_depth_sr50a'].sel(station = i) , color = 'lightblue', linewidth = 1, zorder = 5)\n",
    "    ax2.plot (xr['time'],xr['snow_depth_avg_sdms40'].sel(station = i) , color = 'darkblue', linewidth = 1, zorder = 5)\n",
    "    ax2.axhline(y=-.05, color='red', linestyle='--')\n",
    "    ax2.axhline(y=.05, color='red', linestyle='--')  \n",
    "    ax2.set_ylim(-2,2)\n",
    "\n",
    "    # Temperature Figure\n",
    "    ax3 = fig.add_subplot(5,1,3)\n",
    "    ax3.set_ylabel ('Temperature ($^\\circ$C)', fontsize = 13)\n",
    "    ax3.grid(color='black',linewidth=0.3)\n",
    "    ax3.plot (xr['time'],xr['temp_2m'].sel(station = i) , color = 'red', linewidth = 1, zorder = 5)\n",
    "    ax3.axhline(y=0, color='red', linestyle='--')\n",
    "\n",
    "    # Precipitation\n",
    "    ax4 = fig.add_subplot(5,1,4)\n",
    "    ax4.set_ylabel ('Precipitation (hotplate) (mm)', fontsize = 13)\n",
    "    ax4.grid(color='black',linewidth=0.3)\n",
    "    ax4.plot (xr['time'],xr['precipitation_rate_k63'].sel(station = i) , color = 'blue', linewidth = 1, zorder = 5)\n",
    "    ax4.axhline(y=0.05, color='red', linestyle='--')\n",
    "\n",
    "    # Ice Status \n",
    "    ax5 = fig.add_subplot(5,1,5)\n",
    "    ax5.set_ylabel ('Ice Status', fontsize = 13)\n",
    "    ax5.grid(color='black',linewidth=0.3)\n",
    "    ax5.scatter (xr['time'],xr_ice['ice_status'].sel(station = i) , color = 'pink', linewidth = 1, zorder = 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Managing Observational and HREF Member Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65276/3404357835.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  NYSM_ptype2['ptype'] = NYSM_ptype2['ptype_rain'].astype(float)+NYSM_ptype2['ptype_snow'].astype(float)+NYSM_ptype2['ptype_freezing_rain'].astype(float)+NYSM_ptype2['ptype_unknown'].astype(float)\n"
     ]
    }
   ],
   "source": [
    "# Converting FZRA NYSM .nc files to Pandas Dataframes\n",
    "df_feb_zr = ds_feb_zr.to_dataframe()\n",
    "df_feb_zr = df_feb_zr.reset_index(level=1)\n",
    "df_feb_zr = df_feb_zr.drop(columns=['CS_0871LH1_software_ver','station_name','elevation','CS_0871LH1_SN'])\n",
    "df_feb_zr['time'] = df_feb_zr['time'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "# NYSM WFBM\n",
    "df_feb_zr['latitude'] = np.where(df_feb_zr['latitude'] == 44.393236, 44.393234, df_feb_zr['latitude'])\n",
    "df_feb_zr['longitude'] = np.where(df_feb_zr['longitude'] == -73.858829, -73.858826, df_feb_zr['longitude'])\n",
    "\n",
    "# NYSM ESSX\n",
    "df_feb_zr['latitude'] = np.where(df_feb_zr['latitude'] == 44.313604, 44.313602, df_feb_zr['latitude'])\n",
    "df_feb_zr['longitude'] = np.where(df_feb_zr['longitude'] == -73.371896, -73.371895, df_feb_zr['longitude'])\n",
    "\n",
    "#NYSM CHAZ\n",
    "df_feb_zr['latitude'] = np.where(df_feb_zr['latitude'] == 44.889, 44.89565, df_feb_zr['latitude'])\n",
    "df_feb_zr['longitude'] = np.where(df_feb_zr['longitude'] == -73.46634, -73.46401, df_feb_zr['longitude'])\n",
    "\n",
    "# WINTRE-MIX REGION\n",
    "latN = 46.5\n",
    "latS = 43.75\n",
    "lonW = -77.0\n",
    "lonE = -72.0\n",
    "cLat = (latN + latS)/2\n",
    "cLon = (lonW + lonE )/2\n",
    "\n",
    "#NYSM FZRA\n",
    "ds_coords['station']=np.array([str(stn.values,'utf-8') for stn in ds_coords['station']])\n",
    "\n",
    "# Adding Lat and Lon from 2019 NYSM file to the 2022 Files \n",
    "NYSM_ptype = NYSM_ptype.assign(lat = ds_coords['lat'])\n",
    "NYSM_ptype = NYSM_ptype.assign(lon = ds_coords['lon'])\n",
    "\n",
    "# Converting NYSM .nc files to Pandas Dataframes\n",
    "NYSM_ptype = NYSM_ptype.to_dataframe()\n",
    "NYSM_ptype = NYSM_ptype.reset_index(level=1)\n",
    "\n",
    "# Dropping extra variables \n",
    "NYSM_ptype = NYSM_ptype.drop(['snow_depth_smooth','snow_depth_change_1hr',\n",
    "                              'snow_depth_change_3hr','snow_depth_change_6hr',\n",
    "                              'snow_depth_change_12hr','snow_depth_change_24hr',\n",
    "                              'snow_accumulation_1hr','snow_accumulation_3hr',\n",
    "                              'snow_accumulation_6hr','snow_accumulation_12hr',\n",
    "                              'snow_accumulation_24hr','precip_1hr','precip_3hr',\n",
    "                              'precip_6hr','precip_12hr','precip_24hr','frozen_prop',\n",
    "                              'slr_1hr','slr_3hr','slr_6hr','slr_12hr','slr_24hr',\n",
    "                              'frozen05','frozen25','frozen50'] , axis=1)\n",
    "\n",
    "#Greating the colorbar for the ASOS observations\n",
    "ptype_colors = [(1,1,1,1),'tab:blue','mediumslateblue','darkslateblue','deeppink','darkmagenta','tab:green','darkturquoise','cyan','grey']\n",
    "cmap_ptype_ext = mpl.colors.ListedColormap(ptype_colors)\n",
    "norm_ptype_ext = mpl.colors.BoundaryNorm([-1,0,1,2,3,5,6,8,9,10,11],ncolors = len(ptype_colors))\n",
    "ptype_ticks = [-0.5,0.5,1.5,2.5,4,5.5,7,8.5,9.5,10.5,11.5]\n",
    "ptype_labels = ['NP','SN','IP','IP/SN','ZR','ZR/IP','RA','RA/SN','RA/IP','UP']\n",
    "\n",
    "cbar_ptype = mpl.cm.ScalarMappable(norm = norm_ptype_ext, cmap = cmap_ptype_ext)\n",
    "cbar_ptype.set_array([])\n",
    "\n",
    "# Replacing #'s and letters w/ variables from the ptype map defined above\n",
    "NYSM_ptype['ptype_snow'] = NYSM_ptype['ptype_snow'].replace([0],['NULL'])\n",
    "NYSM_ptype['ptype_rain'] = NYSM_ptype['ptype_rain'].replace([0],['NULL'])\n",
    "NYSM_ptype['ptype_freezing_rain'] = NYSM_ptype['ptype_freezing_rain'].replace([0],['NULL'])\n",
    "NYSM_ptype['ptype_unknown'] = NYSM_ptype['ptype_unknown'].replace([0],['NULL'])\n",
    "NYSM_ptype['ptype_freezing_rain'] = NYSM_ptype['ptype_freezing_rain'].replace(['NULL',1],[-0.1,3.99])\n",
    "NYSM_ptype['ptype_unknown'] = NYSM_ptype['ptype_unknown'].replace(['NULL',1.0],[-0.1,10.99])\n",
    "NYSM_ptype['ptype_rain'] = NYSM_ptype['ptype_rain'].replace(['NULL',1],[-0.1,7.99])\n",
    "NYSM_ptype['ptype_snow'] = NYSM_ptype['ptype_snow'].replace(['NULL',1],[-0.1,0.99])\n",
    "\n",
    "# NYSM_ptype2 = NYSM_ptype[NYSM_ptype['ptype_unknown'] != 0] #uncomment out if you just want to see times where it was precipitating\n",
    "NYSM_ptype2 = NYSM_ptype.dropna() #dropping NaN\n",
    "\n",
    "# Adding together #'s we mapped for ptype into one column.\n",
    "NYSM_ptype2['ptype'] = NYSM_ptype2['ptype_rain'].astype(float)+NYSM_ptype2['ptype_snow'].astype(float)+NYSM_ptype2['ptype_freezing_rain'].astype(float)+NYSM_ptype2['ptype_unknown'].astype(float)\n",
    "\n",
    "# Cropping Data\n",
    "NYSM_ptype_cropped = NYSM_ptype2[\n",
    "    (NYSM_ptype2[\"lat\"] <= latN) & \n",
    "    (NYSM_ptype2[\"lat\"] >= latS) & \n",
    "    (NYSM_ptype2[\"lon\"] >= lonW) & \n",
    "    (NYSM_ptype2[\"lon\"] <= lonE)]\n",
    "\n",
    "valid_time = datetime(year,month,day,hour,minute)\n",
    "valid_time_str = valid_time.strftime(\"%Y-%m-%d %H:%M\") \n",
    "hr = valid_time+dt.timedelta(minutes=minute_delta)\n",
    "time = hr.strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "# mPING\n",
    "\n",
    "#**********\n",
    "#Setup variables\n",
    "var_name = 'mping' #used in plot filename\n",
    "\n",
    "api_key = '96edae02d51f0bf079e7fee0974837c3908f9e9e'\n",
    "\n",
    "interval_min = 60 #60\n",
    "interval_minstr = str(interval_min)\n",
    "#**********\n",
    "\n",
    "imgdir = f'images/' #location to save images\n",
    "if not os.path.exists(imgdir):\n",
    "    os.makedirs(imgdir)\n",
    "#imgdir = '' #uncomment to save in current directory\n",
    "\n",
    "def get_mping_obs(adjtime, interval_min = interval_min, time_window = 'center'):\n",
    "    '''Retrieve mPING observations and parse into a pandas DataFrame\n",
    "    Inputs: \n",
    "        adjtime (datetime object) - desired observation time\n",
    "        interval_min (int) - range of time in minutes to get observations  \n",
    "        time_window (\"begin\", \"center\" or \"end\") \n",
    "            - \"begin\": get obs for interval_min beginning at adjtime\n",
    "            - \"center\": get obs centered on adjtime\n",
    "            - \"end\": get obs for interval_min ending at adjtime\n",
    "    Return:\n",
    "        pandas DataFrame with nicely parsed obs'''\n",
    "    \n",
    "    reqheaders = {\n",
    "    'content-type': 'application/json',\n",
    "    'Authorization': f'Token {api_key}',\n",
    "    }\n",
    "    \n",
    "    #Form API query URL\n",
    "    mping_url_base = 'http://mping.ou.edu/mping/api/v2/reports'\n",
    "    \n",
    "    #Add filters to base URL\n",
    "    if time_window == 'begin':\n",
    "        #get all reports for time interval beginning at valid time\n",
    "        mping_start = adjtime\n",
    "        mping_end = adjtime + timedelta(minutes = interval_min)\n",
    "        mping_url = f'{mping_url_base}?obtime_gte={mping_start:%Y-%m-%d %H:%M:%S}&obtime_lt={mping_end:%Y-%m-%d %H:%M:%S}'\n",
    "        #print (mping_url)\n",
    "    elif time_window == 'end':\n",
    "        #get all reports for 1h preceding valid time\n",
    "        #mping_valid = adjtime - timedelta(minutes = interval_min)\n",
    "        #mping_url = f'{mping_url_base}?year={mping_valid:%Y}&month={mping_valid:%-m}&day={mping_valid:%-d}&hour={mping_valid:%-H}'\n",
    "        #get all reports for time interval ending at valid time\n",
    "        mping_start = adjtime - timedelta(minutes = interval_min)\n",
    "        mping_end = adjtime\n",
    "        mping_url = f'{mping_url_base}?obtime_gt={mping_start:%Y-%m-%d %H:%M:%S}&obtime_lte={mping_end:%Y-%m-%d %H:%M:%S}'\n",
    "        #print (mping_url)\n",
    "    elif time_window == 'center':\n",
    "        #get all reports for time interval centered on valid time\n",
    "        mping_start = adjtime - timedelta(minutes = interval_min//2)\n",
    "        mping_end = adjtime + timedelta(minutes = interval_min//2)\n",
    "        mping_url = f'{mping_url_base}?obtime_gte={mping_start:%Y-%m-%d %H:%M:%S}&obtime_lt={mping_end:%Y-%m-%d %H:%M:%S}'\n",
    "        #print (mping_url)\n",
    "     \n",
    "    #Retrieve JSON data\n",
    "    response = requests.get(mping_url, headers = reqheaders)\n",
    "    if response.status_code != 200:\n",
    "        print (f'request failed with status code {response.status_code}')\n",
    "        return\n",
    "    else:\n",
    "        data = response.json()\n",
    "        print (f'mPING Valid: {adjtime:%Y-%m-%d %H:%M} UTC (Retrieved {data[\"count\"]} Reports over the past {interval_minstr} minutes)')\n",
    "    \n",
    "    #Read mPING json into dataframe for easier filtering\n",
    "    df = pd.DataFrame.from_dict(data['results'])\n",
    "    #Parse out lat/lon data\n",
    "    df['longitude'] = [geom['coordinates'][0] for geom in df['geom']]\n",
    "    df['latitude'] = [geom['coordinates'][1] for geom in df['geom']]\n",
    "    \n",
    "    #could stop here\n",
    "    #return df\n",
    "    \n",
    "    #Also map mPING p-types to p-type values/colors used in colorbar\n",
    "    mping_types_map_m = {'NULL': 0,\n",
    "                      'Snow and/or Graupel': 1,\n",
    "                      'Ice Pellets/Sleet': 2,\n",
    "                      'Mixed Ice Pellets and Snow': 3,\n",
    "                      'Freezing Rain': 4,\n",
    "                      'Freezing Drizzle': 4, #don't have separate category for this currently\n",
    "                      'Mixed Freezing Rain and Ice Pellets': 6,\n",
    "                      'Rain': 8, \n",
    "                      'Drizzle': 8, #don't have separate category for this\n",
    "                      'Mixed Rain and Snow': 9,\n",
    "                      'Mixed Rain and Ice Pellets': 10,\n",
    "                      }\n",
    "    #map indexes to colors (optional: only works if continuous value HRRRE colorbar used)\n",
    "    #mping_colors_map = {k:ptype_colors[int(v)] for k,v in mping_types_map.items()}\n",
    "    \n",
    "    #Subtract 0.01 to make p-type categories correct\n",
    "    df['ptype'] = df['description'].map(mping_types_map_m) - 0.01\n",
    "    #df['ptype_colors'] = df['description'].map(mping_colors_map)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ASOS\n",
    "\n",
    "dfs = [df_NY, df_ON, df_QE, df_VT] #Combining the ASOS dataframes from selected stations in Ontario, Quebec, and NY\n",
    "df_merged = pd.concat(dfs)\n",
    "\n",
    "#defining the map for what we are going to map the precip types (#'s) to\n",
    "precip_types_map = {'NULL': -0.1,\n",
    "                      'Snow and/or Graupel': 0.99,\n",
    "                      'Ice Pellets/Sleet': 1.99,\n",
    "                      'Mixed Ice Pellets and Snow': 2.99,\n",
    "                      'Freezing Rain': 3.99,\n",
    "                      'Freezing Drizzle': 3.99, #don't have separate category for this currently\n",
    "                      'Mixed Freezing Rain and Ice Pellets': 5.99,\n",
    "                      'Rain': 7.99, \n",
    "                      'Drizzle': 7.99, #don't have separate category for this\n",
    "                      'Mixed Rain and Snow': 8.99,\n",
    "                      'Mixed Rain and Ice Pellets': 9.99,\n",
    "                      'Unknown Precip': 10.99\n",
    "                      }\n",
    "\n",
    "#Replacing all of the metar codes with the easier to read map language, this is also used to coencide with the MPING data better as we will use the same language between both\n",
    "df_merged['wxcodes'] = df_merged['wxcodes'].replace(['NP','M','NaN','DRSN', 'BR','FG', 'HZ', 'FZFG'],\n",
    "                                                   ['NULL','NULL','NULL', 'NULL', 'NULL','NULL', 'NULL','NULL'])\n",
    "    \n",
    "df_merged['wxcodes'] = df_merged['wxcodes'].replace(['NULL','-SN','-SN BR','SN','-SN DRSN','-SNBR','+SN','SN FZFG'],\n",
    "                                                     ['NULL','Snow and/or Graupel','Snow and/or Graupel','Snow and/or Graupel','Snow and/or Graupel','Snow and/or Graupel', 'Snow and/or Graupel','Snow and/or Graupel'])\n",
    "\n",
    "df_merged['wxcodes'] = df_merged['wxcodes'].replace(['-IP','IP','+IP'],['Ice Pellets/Sleet','Ice Pellets/Sleet','Ice Pellets/Sleet']) \n",
    "\n",
    "df_merged['wxcodes'] = df_merged['wxcodes'].replace(['-RA','RA','+RA','RA BR','-RA FG','-DZ BR','-DZ FG','DZ BR','-RA BR','DZ FG','RA FG','-SHGS','+RA BR','VCSH'],\n",
    "                                                    ['Rain','Rain','Rain','Rain','Rain','Rain','Rain','Rain','Rain','Rain','Rain','Rain','Rain','Rain']) \n",
    "\n",
    "df_merged['wxcodes'] = df_merged['wxcodes'].replace(['FZDZ FZFG','FZRA FG','FZRA','-FZDZ','-FZDZ BR','-FZRA','+FZRA','-FZRA BR','FZDZ','FZRA BR'],\n",
    "                                                    ['Freezing Rain','Freezing Rain','Freezing Rain','Freezing Rain','Freezing Rain','Freezing Rain','Freezing Rain','Freezing Rain','Freezing Rain','Freezing Rain'])\n",
    "\n",
    "df_merged['wxcodes'] = df_merged['wxcodes'].replace(['-FZRA -PL','-FZRAPL BR','-FZRA -PL DRSN'],['Mixed Freezing Rain and Ice Pellets','Mixed Freezing Rain and Ice Pellets','Mixed Freezing Rain and Ice Pellets'])\n",
    "\n",
    "df_merged['wxcodes'] = df_merged['wxcodes'].replace(['-SHSN','-FZRA -SN DRSN'],['Mixed Rain and Snow','Mixed Rain and Snow']) \n",
    "\n",
    "df_merged['wxcodes'] = df_merged['wxcodes'].replace(['-SNPL DRSN', '-PLSN DRSN'],['Mixed Ice Pellets and Snow','Mixed Ice Pellets and Snow']) \n",
    "\n",
    "df_merged['wxcodes'] = df_merged['wxcodes'].replace(['UP','-UP'],['Unknown Precip','Unknown Precip']) \n",
    "\n",
    "    \n",
    "df_merged['ptype'] = df_merged['wxcodes'].map(precip_types_map) \n",
    "\n",
    "df_merged_cropped = df_merged[\n",
    "    (df_merged[\"lat\"] <= latN) & \n",
    "    (df_merged[\"lat\"] >= latS) & \n",
    "    (df_merged[\"lon\"] >= lonW) & \n",
    "    (df_merged[\"lon\"] <= lonE)\n",
    "]\n",
    "\n",
    "# HREF\n",
    "\n",
    "# Snow Colorbar\n",
    "ptype_colors_snow = [(1,1,1), 'tab:blue']\n",
    "cmap_ptype_ext_snow = mpl.colors.ListedColormap(ptype_colors_snow)\n",
    "my_cmap = cmap_ptype_ext_snow(np.arange(cmap_ptype_ext_snow.N))\n",
    "my_cmap[:,-1] = np.linspace(0, 1, cmap_ptype_ext_snow.N)\n",
    "my_cmap_snow = ListedColormap(my_cmap)\n",
    "\n",
    "# Ice Colorbar\n",
    "ptype_colors_icep = [(1,1,1), 'mediumslateblue']\n",
    "cmap_ptype_ext_icep = mpl.colors.ListedColormap(ptype_colors_icep)\n",
    "my_cmap = cmap_ptype_ext_icep(np.arange(cmap_ptype_ext_icep.N))\n",
    "my_cmap[:,-1] = np.linspace(0, 1, cmap_ptype_ext_icep.N)\n",
    "my_cmap_icep = ListedColormap(my_cmap)\n",
    "\n",
    "# Ice / Snow Colorbar\n",
    "ptype_colors_snow_icep = [(1,1,1), 'darkslateblue']\n",
    "cmap_ptype_ext_snow_icep = mpl.colors.ListedColormap(ptype_colors_snow_icep)\n",
    "my_cmap = cmap_ptype_ext_snow_icep(np.arange(cmap_ptype_ext_snow_icep.N))\n",
    "my_cmap[:,-1] = np.linspace(0, 1, cmap_ptype_ext_snow_icep.N)\n",
    "my_cmap_icep_snow = ListedColormap(my_cmap)\n",
    "\n",
    "# Freezing Rain Colorbar\n",
    "ptype_colors_fzra = [(1,1,1), 'deeppink']\n",
    "cmap_ptype_ext_fzra = mpl.colors.ListedColormap(ptype_colors_fzra)\n",
    "my_cmap = cmap_ptype_ext_fzra(np.arange(cmap_ptype_ext_fzra.N))\n",
    "my_cmap[:,-1] = np.linspace(0, 1, cmap_ptype_ext_fzra.N)\n",
    "my_cmap_fzra = ListedColormap(my_cmap)\n",
    "\n",
    "# Freezing Rain / Ice Colorbar\n",
    "ptype_colors_fzra_icep = [(1,1,1), 'darkmagenta']\n",
    "cmap_ptype_ext_fzra_icep = mpl.colors.ListedColormap(ptype_colors_fzra_icep)\n",
    "my_cmap = cmap_ptype_ext_fzra_icep(np.arange(cmap_ptype_ext_fzra_icep.N))\n",
    "my_cmap[:,-1] = np.linspace(0, 1, cmap_ptype_ext_fzra_icep.N)\n",
    "my_cmap_fzra_icep = ListedColormap(my_cmap)\n",
    "\n",
    "# Rain Colorbar\n",
    "ptype_colors_rain = [(1,1,1), 'tab:green']\n",
    "cmap_ptype_ext_rain = mpl.colors.ListedColormap(ptype_colors_rain)\n",
    "my_cmap = cmap_ptype_ext_rain(np.arange(cmap_ptype_ext_rain.N))\n",
    "my_cmap[:,-1] = np.linspace(0, 1, cmap_ptype_ext_rain.N)\n",
    "my_cmap_rain = ListedColormap(my_cmap)\n",
    "\n",
    "# Rain / Ice\n",
    "ptype_colors_rain_icep = [(1,1,1), 'cyan']\n",
    "cmap_ptype_ext_rain_icep = mpl.colors.ListedColormap(ptype_colors_rain_icep)\n",
    "my_cmap = cmap_ptype_ext_rain_icep(np.arange(cmap_ptype_ext_rain_icep.N))\n",
    "my_cmap[:,-1] = np.linspace(0, 1, cmap_ptype_ext_rain_icep.N)\n",
    "my_cmap_rain_icep = ListedColormap(my_cmap)\n",
    "\n",
    "#Rain / Snow\n",
    "ptype_colors_rain_snow= [(1,1,1),'darkturquoise']\n",
    "cmap_ptype_ext_rain_snow = mpl.colors.ListedColormap(ptype_colors_rain_snow)\n",
    "my_cmap = cmap_ptype_ext_rain_snow(np.arange(cmap_ptype_ext_rain_snow.N))\n",
    "my_cmap[:,-1] = np.linspace(0,1, cmap_ptype_ext_rain_snow.N)\n",
    "my_cmap_rain_snow = ListedColormap(my_cmap)\n",
    "norm_ptype = mpl.colors.BoundaryNorm([0,1.1,2.1],ncolors = len(ptype_colors_rain_snow));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5 Pannel Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading In Observational Data...\n",
      "mPING Valid: 2022-02-23 03:00 UTC (Retrieved 102 Reports over the past 60 minutes)\n",
      "ASOS Valid: 2022-02-23 03:00 UTC\n",
      "NYSM Valid: 2022-02-23 03:00 UTC\n",
      "SENT Valid: 2022-02-23 03:00 UTC\n",
      "NYSM FZRA Valid: 2022-02-23 03:00 UTC Series([], Name: ice_sum, dtype: float32)\n",
      "\n",
      "Loading In HREF Data...\n",
      "ARW Valid: 2022-02-23 03:00 UTC\n",
      "FV3 Valid: 2022-02-23 03:00 UTC\n",
      "NSSL Valid: 2022-02-23 03:00 UTC\n",
      "NCEP Valid: 2022-02-23 03:00 UTC\n",
      "NAM Valid: 2022-02-23 03:00 UTC\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/network/rit/lab/snowclus/anaconda3_2021/envs/may21/lib/python3.8/site-packages/cartopy/mpl/geoaxes.py:1752: UserWarning: You passed a edgecolor/edgecolors ('black') for an unfilled marker (7).  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  result = matplotlib.axes.Axes.scatter(self, *args, **kwargs)\n",
      "/network/rit/lab/snowclus/anaconda3_2021/envs/may21/lib/python3.8/site-packages/cartopy/mpl/geoaxes.py:1797: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n",
      "  result = matplotlib.axes.Axes.pcolormesh(self, *args, **kwargs)\n",
      "/network/rit/lab/snowclus/anaconda3_2021/envs/may21/lib/python3.8/site-packages/cartopy/crs.py:825: ShapelyDeprecationWarning: __len__ for multi-part geometries is deprecated and will be removed in Shapely 2.0. Check the length of the `geoms` property instead to get the  number of parts of a multi-part geometry.\n",
      "  if len(multi_line_string) > 1:\n",
      "/network/rit/lab/snowclus/anaconda3_2021/envs/may21/lib/python3.8/site-packages/cartopy/crs.py:877: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for line in multi_line_string:\n",
      "/network/rit/lab/snowclus/anaconda3_2021/envs/may21/lib/python3.8/site-packages/cartopy/crs.py:944: ShapelyDeprecationWarning: __len__ for multi-part geometries is deprecated and will be removed in Shapely 2.0. Check the length of the `geoms` property instead to get the  number of parts of a multi-part geometry.\n",
      "  if len(p_mline) > 0:\n",
      "/network/rit/lab/snowclus/anaconda3_2021/envs/may21/lib/python3.8/site-packages/cartopy/crs.py:982: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  line_strings.extend(multi_line_string)\n",
      "/network/rit/lab/snowclus/anaconda3_2021/envs/may21/lib/python3.8/site-packages/cartopy/crs.py:982: ShapelyDeprecationWarning: __len__ for multi-part geometries is deprecated and will be removed in Shapely 2.0. Check the length of the `geoms` property instead to get the  number of parts of a multi-part geometry.\n",
      "  line_strings.extend(multi_line_string)\n",
      "/network/rit/lab/snowclus/anaconda3_2021/envs/may21/lib/python3.8/site-packages/cartopy/crs.py:836: ShapelyDeprecationWarning: __len__ for multi-part geometries is deprecated and will be removed in Shapely 2.0. Check the length of the `geoms` property instead to get the  number of parts of a multi-part geometry.\n",
      "  line_strings = list(multi_line_string)\n",
      "/network/rit/lab/snowclus/anaconda3_2021/envs/may21/lib/python3.8/site-packages/cartopy/crs.py:836: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  line_strings = list(multi_line_string)\n"
     ]
    }
   ],
   "source": [
    "for i in fhrs:\n",
    "\n",
    "    # Time \n",
    "    D = int(((i-starthour)/inc)) # Used for HREF File Reference  \n",
    "    time = (hr) + timedelta(hours=float(i)) \n",
    "    adjtime = time - dt.timedelta(minutes=minute_delta)\n",
    "    adjtimestr = adjtime.strftime(\"%Y-%m-%d %H:%M\") \n",
    "    nysm_adjtime = time.strftime(\"%H:%M\")\n",
    "    time_delta = (hr) - timedelta(hours=hour_delta, minutes=minute_delta)\n",
    "    time_delta_str = time_delta.strftime(\"%Y-%m-%d %H:%M\") \n",
    "    titlestrend = adjtime.strftime(\"%Y-%m-%d %H:%M\")\n",
    "    time_fzra_begin= (adjtime) - timedelta(hours=0, minutes=30)\n",
    "    time_fzra_end= (adjtime) - timedelta(hours=0, minutes=-30)\n",
    "\n",
    "    # Observational Data\n",
    "    print(\"Loading In Observational Data...\")\n",
    "    \n",
    "    # MPING\n",
    "    df = get_mping_obs(adjtime, interval_min = interval_min, time_window = 'end')\n",
    "    \n",
    "    # ASOS\n",
    "    mask_ASOS = (df_merged_cropped['valid'] > time_delta_str) & (df_merged_cropped['valid'] <= adjtimestr)\n",
    "    ASOS_cropped = df_merged_cropped.loc[mask_ASOS]\n",
    "    df_merged = ASOS_cropped.drop_duplicates(subset='station', keep='last', inplace=False)\n",
    "    df_merged = df_merged.dropna()\n",
    "    lats_ASOS_ptype = df_merged['lat']\n",
    "    lons_ASOS_ptype = df_merged['lon']\n",
    "    ptype_ASOS = df_merged['ptype']\n",
    "    print(\"ASOS Valid: \" + adjtimestr + ' UTC')\n",
    "    \n",
    "    # NYSM\n",
    "    mask_NYSM = (NYSM_ptype_cropped['time_5M'] > time_delta_str) & (NYSM_ptype_cropped['time_5M'] <= adjtimestr)\n",
    "    NYSM_ptype_mask = NYSM_ptype_cropped.loc[mask_NYSM]\n",
    "    NYSM_ptype_lat = NYSM_ptype_mask['lat']\n",
    "    NYSM_ptype_lon = NYSM_ptype_mask['lon']\n",
    "    NYSM_ptype = NYSM_ptype_mask['ptype'].astype(float)\n",
    "    print('NYSM Valid: '+ adjtimestr + ' UTC')\n",
    "    \n",
    "    #Sentinal\n",
    "    mask_SENT = (PTYPE_df['time'] > time_delta_str) & (PTYPE_df['time'] <= adjtimestr)\n",
    "    SENT_ptype_mask = PTYPE_df.loc[mask_SENT]\n",
    "    A_ptype_lat = SENT_ptype_mask['A_lat']\n",
    "    A_ptype_lon = SENT_ptype_mask['A_lon']\n",
    "    A_PTYPE = SENT_ptype_mask['ARBO'].astype(float)\n",
    "    G_ptype_lat = SENT_ptype_mask['G_lat']\n",
    "    G_ptype_lon = SENT_ptype_mask['G_lon']\n",
    "    G_PTYPE =  SENT_ptype_mask['GAUL'].astype(float) #+ 3.9\n",
    "    U_ptype_lat =  SENT_ptype_mask['U_lat']\n",
    "    U_ptype_lon =  SENT_ptype_mask['U_lon']\n",
    "    U_PTYPE =  SENT_ptype_mask['UQAM'].astype(float)\n",
    "    T_ptype_lat =  SENT_ptype_mask['T_lat']\n",
    "    T_ptype_lon =  SENT_ptype_mask['T_lon']\n",
    "    T_PTYPE =  SENT_ptype_mask['TROI'].astype(float)#+10\n",
    "    print('SENT Valid: '+ adjtimestr + ' UTC')\n",
    "\n",
    "    # FZRA\n",
    "    mask_NYSM_zr = ((df_feb_zr[\"time\"] > str(time_fzra_begin)) & (df_feb_zr[\"time\"] < str(time_fzra_end)))\n",
    "    df_feb_zr_mask = df_feb_zr.loc[mask_NYSM_zr]\n",
    "    NYSM_zr = df_feb_zr_mask\n",
    "   #NYSM_zr = NYSM_zr.groupby([\"station\",'latitude','longitude'], as_index=False).agg(ice_sum=(\"T_i_method_2\", \"sum\"))\n",
    "    NYSM_zr = NYSM_zr.groupby([\"station\",'latitude','longitude'], as_index=False).agg(ice_sum=(\"Icing_flag\", \"sum\"))\n",
    "    NYSM_zr = NYSM_zr[NYSM_zr['ice_sum'] != 0] #uncomment out if you just want to see times where it was precipitating\n",
    "    lats_NYSM_zr = NYSM_zr['latitude']\n",
    "    lons_NYSM_zr = NYSM_zr['longitude']\n",
    "    NYSM_zr = NYSM_zr['ice_sum']\n",
    "    print('NYSM FZRA Valid: '+ adjtimestr + ' UTC', NYSM_zr)\n",
    "    print()\n",
    "    \n",
    "    # HREF \n",
    "    import xarray as xr\n",
    "    print(\"Loading In HREF Data...\")\n",
    "    hrefN, hrefS, hrefE, hrefW = latN+.7, latS-.9, lonE+360.5 , lonW+359\n",
    " \n",
    "    # ARW RA\n",
    "    with xr.open_mfdataset(arw[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260029}) as arw_cr:\n",
    "        arw_rain = arw_cr['crain'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "\n",
    "    #ARW FZRA\n",
    "    with xr.open_mfdataset(arw[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260030}) as arw_cf:\n",
    "        arw_fzra = arw_cf['cfrzr'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "\n",
    "    # ARW PL\n",
    "    with xr.open_mfdataset(arw[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260031}) as arw_ip:\n",
    "        arw_icep = arw_ip['cicep'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "\n",
    "    # ARW SN\n",
    "    with xr.open_mfdataset(arw[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260032}) as arw_sn:\n",
    "        arw_snow = arw_sn['csnow'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "        print('ARW Valid: '+ adjtimestr + ' UTC')\n",
    "              \n",
    "    # FV3 RA\n",
    "    with xr.open_mfdataset(fv3[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260029}) as fv3_cr:\n",
    "        fv3_rain = fv3_cr['crain'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "\n",
    "    # FV3 FZRA\n",
    "    with xr.open_mfdataset(fv3[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260030}) as fv3_cf:\n",
    "        fv3_fzra = fv3_cf['cfrzr'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "\n",
    "    # FV3 PL\n",
    "    with xr.open_mfdataset(fv3[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260031}) as fv3_ip:\n",
    "        fv3_icep = fv3_ip['cicep'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "\n",
    "    # FV3 SN\n",
    "    with xr.open_mfdataset(fv3[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260032}) as fv3_sn:\n",
    "        fv3_snow = fv3_sn['csnow'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "        print('FV3 Valid: '+ adjtimestr + ' UTC')\n",
    " \n",
    "    # NSSL RA\n",
    "    with xr.open_mfdataset(nssl[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260029}) as nssl_cr:\n",
    "        nssl_rain = nssl_cr['crain'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "\n",
    "    # NSSL FZRA\n",
    "    with xr.open_mfdataset(nssl[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260030}) as nssl_cf:\n",
    "        nssl_fzra = nssl_cf['cfrzr'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "\n",
    "    # NSSL PL\n",
    "    with xr.open_mfdataset(nssl[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260031}) as nssl_ip:\n",
    "        nssl_icep = nssl_ip['cicep'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "\n",
    "    # NSSL SN\n",
    "    with xr.open_mfdataset(nssl[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260032}) as nssl_sn:\n",
    "        nssl_snow = nssl_sn['csnow'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "        print('NSSL Valid: '+ adjtimestr + ' UTC')\n",
    "         \n",
    "    # NCEP RA\n",
    "    with xr.open_mfdataset(ncep[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260029}) as ncep_cr:\n",
    "        ncep_rain = ncep_cr['crain'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "\n",
    "    # NCEP FZRA\n",
    "    with xr.open_mfdataset(ncep[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260030}) as ncep_cf:\n",
    "        ncep_fzra = ncep_cf['cfrzr'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "\n",
    "    # NCEP PL\n",
    "    with xr.open_mfdataset(ncep[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260031}) as ncep_ip:\n",
    "        ncep_icep = ncep_ip['cicep'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "\n",
    "    # NCEP SN\n",
    "    with xr.open_mfdataset(ncep[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260032}) as ncep_sn:\n",
    "        ncep_snow = ncep_sn['csnow'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "        print('NCEP Valid: '+ adjtimestr + ' UTC')\n",
    "         \n",
    "    # NAM RA\n",
    "    with xr.open_mfdataset(nam[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260029}) as nam_cr:\n",
    "        nam_rain = nam_cr['crain'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "\n",
    "    # NAM FZRA\n",
    "    with xr.open_mfdataset(nam[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260030}) as nam_cf:\n",
    "        nam_fzra = nam_cf['cfrzr'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "\n",
    "    # NAM PL\n",
    "    with xr.open_mfdataset(nam[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260031}) as nam_ip:\n",
    "        nam_icep = nam_ip['cicep'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "\n",
    "    # NAM SN\n",
    "    with xr.open_mfdataset(nam[D],engine = 'cfgrib',filter_by_keys={'stepType': 'instant','typeOfLevel': 'surface','paramId':260032}) as nam_sn:\n",
    "        nam_snow = nam_sn['csnow'].where((arw_cr.latitude >= hrefS) & (arw_cr.latitude <= hrefN) & (arw_cr.longitude >= hrefW) & (arw_cr.longitude <= hrefE))\n",
    "        print('NAM Valid: '+ adjtimestr + ' UTC')\n",
    "        print()\n",
    "     \n",
    "    # Deriving Precipitation Type from combinations of NCEP catagorical precip\n",
    "    ncep_icep_fzra = np.add(ncep_icep,ncep_fzra)\n",
    "    ncep_icep_snow = np.add(ncep_icep,ncep_snow)\n",
    "    ncep_rain_snow = np.add(ncep_rain,ncep_snow)\n",
    "    ncep_rain_icep = np.add(ncep_rain,ncep_icep)\n",
    "    \n",
    "    # Defining a random variable to make a Latitude and Longitude we can use for plotting HREF members and their catagories\n",
    "    lats = arw_rain['latitude']\n",
    "    lons = arw_rain['longitude']\n",
    "    \n",
    "    # Defining Basic Plot Features\n",
    "    def features(ax):\n",
    "        ax.set_extent ([lonW,lonE,latS,latN]) # Cartopy Land\n",
    "        norm = mpl.colors.Normalize(-10, 100)\n",
    "        ax.add_feature (cfeature.LAND.with_scale(res), zorder=1) # Cartopy Land\n",
    "        ax.add_feature (cfeature.OCEAN.with_scale(res), zorder=1) # Cartopy Ocean\n",
    "        ax.add_feature (cfeature.LAKES.with_scale(res), zorder=1) # Cartopy Lakes\n",
    "        ax.add_feature (cfeature.COASTLINE.with_scale(res), zorder = 3) # Cartopy Coastline\n",
    "        ax.add_feature (cfeature.STATES.with_scale(res), zorder = 3) # Cartopy US State Boundaries\n",
    "        ax.add_feature(USCOUNTIES.with_scale(county_scale),zorder= 3, linewidth = county_lw) # Cartopy US County Boundaries\n",
    "        ax.scatter(sites['lon'], sites['lat'], s = msize, c = 'black', marker = \"$K$\" , transform = ccrs.PlateCarree(), zorder = 4, label= 'WINTRE-MIX Sites') # Plotting WINTRE-MIX Sites\n",
    "        ax.scatter(lons_NYSM_zr, lats_NYSM_zr, marker = 7,s = msize+1, c = 'deeppink', cmap = my_cmap_fzra, norm=norm,transform = ccrs.PlateCarree(), linewidths=2, zorder = 5, edgecolor=color) # Plotting NYSM FZRA Rings\n",
    "        ax.scatter(NYSM_ptype_lon, NYSM_ptype_lat, s = msize, c = NYSM_ptype, cmap = cmap_ptype_ext,norm = norm_ptype_ext, transform = ccrs.PlateCarree(), zorder = 4, label='NYSM', edgecolor=color) # Plotting NYSM Sites and Data\n",
    "        ax.scatter(df['longitude'], df['latitude'], s = msize, c = df['ptype'], cmap = cmap_ptype_ext, norm = norm_ptype_ext, transform = ccrs.PlateCarree(), zorder = 6, label='MPING', marker='d', edgecolor=color) # Plotting mPING Reports\n",
    "        ax.scatter(lons_ASOS_ptype, lats_ASOS_ptype, s = msize, c = ptype_ASOS, cmap = cmap_ptype_ext, norm = norm_ptype_ext, transform = ccrs.PlateCarree(), zorder = 4, marker='s', label='ASOS', edgecolor=color) # Plotting ASOS Sites and Data\n",
    "        ax.scatter(lons_OBS, lats_OBS, s = msize, c='black', transform = ccrs.PlateCarree(), zorder = 4, marker = \"$X$\", label= 'OBS',edgecolor=color)  \n",
    "        ax.scatter(A_ptype_lon, A_ptype_lat, s = msize, c = A_PTYPE, cmap = cmap_ptype_ext, norm = norm_ptype_ext, transform = ccrs.PlateCarree(), zorder = 6, label='SENT',marker='D', edgecolor=color) # Plotting NYSM Sites and Data\n",
    "        ax.scatter(G_ptype_lon, G_ptype_lat, s = msize, c = G_PTYPE, cmap = cmap_ptype_ext, norm = norm_ptype_ext, transform = ccrs.PlateCarree(), zorder = 6, label='SENT',marker='D', edgecolor=color) # Plotting NYSM Sites and Data\n",
    "        ax.scatter(U_ptype_lon, U_ptype_lat, s = msize, c = U_PTYPE, cmap = cmap_ptype_ext, norm = norm_ptype_ext, transform = ccrs.PlateCarree(), zorder = 6, label='SENT',marker='D', edgecolor=color) # Plotting NYSM Sites and Data\n",
    "        ax.scatter(T_ptype_lon, T_ptype_lat, s = msize, c = T_PTYPE, cmap = cmap_ptype_ext, norm = norm_ptype_ext, transform = ccrs.PlateCarree(), zorder = 6, label='SENT',marker='D', edgecolor=color) # Plotting NYSM Sites and Data\n",
    "\n",
    "    def legend(ax):\n",
    "        ASOS = mlines.Line2D([], [], color=c, marker='s', ls='', label='ASOS', markeredgecolor=color) # ASOS legend definition\n",
    "        NYSM = mlines.Line2D([], [], color=c, marker='o', ls='', label='NYSM', markeredgecolor=color) # NYSM legend definition\n",
    "        ICED = mlines.Line2D([], [], color=c, marker= 'v' , ls='', label='NYSM ICE', markeredgecolor=color) # NYSM legend definition\n",
    "        WINTRE_MIX = mlines.Line2D([], [], color=c, marker='$X$', ls='', label='WINTRE-MIX', markeredgecolor=color) # WINTRE-MIX legend definition\n",
    "        MPING = mlines.Line2D([], [], color=c, marker='d', ls='', label='mPING', markeredgecolor=color) # mPING legend definition\n",
    "        SENTINAL = mlines.Line2D([], [], color=c, marker='D', ls='', label='Sentinel', markeredgecolor=color)\n",
    "        ax.legend(loc='upper center',handles=[NYSM, ASOS, MPING, SENTINAL, WINTRE_MIX, ICED],frameon=True,fontsize=20,shadow = False,edgecolor = 'black',mode = \"expand\", ncol = 6,markerscale=2.5,bbox_to_anchor=(0.45, -.05, 1.2,1.24))\n",
    "\n",
    "    # Text\n",
    "    tl0 = 'High Resolution Essemble Forecast System'\n",
    "    tl1 = 'Observations from NYSM, ASOS, CFI Climate Sentinels, & mPING'\n",
    "    tl2 = f'Initilized: {valid_time_str} UTC, Forecast Hour: [{i}], Valid: {titlestrend} UTC'    \n",
    "    title_line = (tl0+ '\\n' + tl2 + '\\n' + tl1)\n",
    "    variable = 'Precipitation Type (p-type)'\n",
    "    model1_t = 'WRF-ARW: ' + variable\n",
    "    model2_t = 'WRF-FV3: ' + variable\n",
    "    model3_t = 'WRF-NSSL: ' + variable\n",
    "    model4_t = 'HRRR NCEP: ' + variable\n",
    "    model5_t = 'NAM NEST: ' + variable\n",
    "    model6_t = 'Observations Only: ' + variable\n",
    "    titletime = valid_time.strftime(\"%Y%m%d%H\") \n",
    "    savefiguretitle = f'5_panel_ptype_{str(titletime)}_{i}'    \n",
    "    \n",
    "    latN = 46.5 # North\n",
    "    latS = 43.75 # South\n",
    "    lonW = -77 # West\n",
    "    lonE = -72 # East\n",
    "    cLat = (latN + latS)/2 # Central Latitude\n",
    "    cLon = (lonW + lonE )/2 # Central Longitude\n",
    "    \n",
    "\n",
    "    \n",
    "    # Figure Parameters\n",
    "    res = '50m' # Resolution\n",
    "    c = 'white' # Color For Interior of legend Symbols\n",
    "    proj = ccrs.LambertConformal(central_longitude=cLon, central_latitude=cLat) # Projection over a central lon. and lat.\n",
    "    msize = 250 # Controls the size of all NYSM, ASOS and mPING \"points\" projected onto the figures\n",
    "    color ='black' # Border Color of all NYSM, ASOS and mPING \"points\"\n",
    "    county_lw, county_scale = 1.0, '5m' # Used to scale the county borders. \n",
    "    o = 25\n",
    "    \n",
    "    # Precipitation Type Figure\n",
    "    fig = plt.figure(figsize=(48,36),dpi=100) # Main Figure SIze and DPI\n",
    "    fig.suptitle(title_line, fontsize = 36) # Main Figure Title\n",
    "    plt.subplots_adjust(hspace = 0.09)#0.09 # Adjusts seperation between subplots (Height)\n",
    "    plt.subplots_adjust(wspace = -0.5)#-0.5 # Adjusts seperation between subplots (Width)\n",
    "    \n",
    "    # NYSM, mPING, ASOS, WINTRE-MIX Sites & ARW Member of HREF\n",
    "    ax1 = fig.add_subplot(3,2,1, projection=proj) # Setting up subplot & projection\n",
    "    ax1.set_title(model1_t,fontsize=o,loc = 'left', fontweight = 'bold') # Title for Individual Pannel\n",
    "    features(ax1) # Plots Observational Reports (mPING, NYSM, ASOS) & Map Features (Land, Water, States, Counties, etc.) \n",
    "    ax1.pcolormesh(lons, lats, arw_rain, cmap = my_cmap_rain, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Rain\n",
    "    ax1.pcolormesh(lons, lats, arw_fzra, cmap = my_cmap_fzra, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Freezing Rain\n",
    "    ax1.pcolormesh(lons, lats, arw_icep, cmap = my_cmap_icep, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Ice Pellets\n",
    "    ax1.pcolormesh(lons, lats, arw_snow, cmap = my_cmap_snow, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Snow\n",
    "    legend(ax1)\n",
    "    \n",
    "    # NYSM, mPING, ASOS, WINTRE-MIX Sites & FV3 Member of HREF\n",
    "    ax2 = fig.add_subplot(3,2,2, projection=proj) # Setting up subplot & projection\n",
    "    ax2.set_title(model2_t,fontsize=o,loc = 'left', fontweight = 'bold') # Title for Individual Pannel\n",
    "    features(ax2) # Plots Observational Reports (mPING, NYSM, ASOS) & Map Features (Land, Water, States, Counties, etc.) \n",
    "    ax2.pcolormesh(lons, lats, fv3_rain, cmap = my_cmap_rain, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Rain\n",
    "    ax2.pcolormesh(lons, lats, fv3_fzra, cmap = my_cmap_fzra, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Freezing Rain\n",
    "    ax2.pcolormesh(lons, lats, fv3_icep, cmap = my_cmap_icep, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Ice Pellets\n",
    "    ax2.pcolormesh(lons, lats, fv3_snow, cmap = my_cmap_snow, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Snow\n",
    "\n",
    "    # NYSM, mPING, ASOS, WINTRE-MIX Sites & NSSL Member of HREF\n",
    "    ax3 = fig.add_subplot(3,2,3, projection=proj) # Setting up subplot & projection\n",
    "    ax3.set_title(model3_t,fontsize=o,loc = 'left', fontweight = 'bold') # Title for Individual Pannel\n",
    "    features(ax3) # Plots Observational Reports (mPING, NYSM, ASOS) & Map Features (Land, Water, States, Counties, etc.) \n",
    "    ax3.pcolormesh(lons, lats, nssl_rain, cmap = my_cmap_rain, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Rain\n",
    "    ax3.pcolormesh(lons, lats, nssl_snow, cmap = my_cmap_snow, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Freezing Rain\n",
    "    ax3.pcolormesh(lons, lats, nssl_fzra, cmap = my_cmap_fzra, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Ice Pellets\n",
    "    ax3.pcolormesh(lons, lats, nssl_icep, cmap = my_cmap_icep, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Snow\n",
    "\n",
    "    # NYSM, mPING, ASOS, WINTRE-MIX Sites & NCEP Member of HREF\n",
    "    ax4 = fig.add_subplot(3,2,4, projection=proj) # Setting up subplot & projection\n",
    "    ax4.set_title(model4_t,fontsize=o,loc = 'left', fontweight = 'bold') # Title for Individual Pannel\n",
    "    features(ax4) # Plots Observational Reports (mPING, NYSM, ASOS) & Map Features (Land, Water, States, Counties, etc.) \n",
    "    ax4.pcolormesh(lons, lats, ncep_rain, cmap = my_cmap_rain, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Rain\n",
    "    ax4.pcolormesh(lons, lats, ncep_fzra, cmap = my_cmap_fzra, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Freezing Rain\n",
    "    ax4.pcolormesh(lons, lats, ncep_icep, cmap = my_cmap_icep, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Ice Pellets\n",
    "    ax4.pcolormesh(lons, lats, ncep_snow, cmap = my_cmap_snow, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Snow\n",
    "    ax4.pcolormesh(lons, lats, ncep_icep_fzra, cmap = my_cmap_fzra_icep, norm = norm_ptype, transform = ccrs.PlateCarree(), zorder = 2) # Derived HREF Member Freezing Rain and Ice Pellets\n",
    "    ax4.pcolormesh(lons, lats, ncep_icep_snow, cmap = my_cmap_icep_snow, norm = norm_ptype, transform = ccrs.PlateCarree(), zorder = 2) # Derived HREF Member Snow and Ice Pellets\n",
    "    ax4.pcolormesh(lons, lats, ncep_rain_snow, cmap = my_cmap_rain_snow, norm = norm_ptype, transform = ccrs.PlateCarree(), zorder = 2) # Derived HREF Member Snow and Rain\n",
    "    ax4.pcolormesh(lons, lats, ncep_rain_icep, cmap = my_cmap_rain_icep, norm = norm_ptype, transform = ccrs.PlateCarree(), zorder = 2) # Derived HREF Member Rain and Ice Pellets\n",
    "\n",
    "    # NYSM, mPING, ASOS, WINTRE-MIX Sites & NAM Member of HREF\n",
    "    ax5 = fig.add_subplot(3,2,5, projection=proj) # Setting up subplot & projection\n",
    "    ax5.set_title(model5_t,fontsize=o,loc = 'left', fontweight = 'bold') # Title for Individual Pannel\n",
    "    features(ax5) # Plots Observational Reports (mPING, NYSM, ASOS) & Map Features (Land, Water, States, Counties, etc.) \n",
    "    ax5.pcolormesh(lons, lats, nam_rain, cmap = my_cmap_rain, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Rain\n",
    "    ax5.pcolormesh(lons, lats, nam_fzra, cmap = my_cmap_fzra, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Freezing Rain\n",
    "    ax5.pcolormesh(lons, lats, nam_icep, cmap = my_cmap_icep, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Ice Pellets\n",
    "    ax5.pcolormesh(lons, lats, nam_snow, cmap = my_cmap_snow, transform = ccrs.PlateCarree(), zorder = 2) # HREF Member Catagorical Snow\n",
    "\n",
    "    # NYSM, mPING, ASOS, WINTRE-MIX Sites & NAM Member of HREF\n",
    "    ax6 = fig.add_subplot(3,2,6, projection=proj) # Setting up subplot & projection\n",
    "    ax6.set_title(model6_t,fontsize=o,loc = 'left', fontweight = 'bold') # Title for Individual Pannel\n",
    "    features(ax6) # Plots Observational Reports (mPING, NYSM, ASOS) & Map Features (Land, Water, States, Counties, etc.) \n",
    "    \n",
    "    # Colorbar\n",
    "    colorbar_axes = fig.add_axes([0.275, 0.1, .476, .0125])# Left Bottom Width Height\n",
    "    cbar = plt.colorbar(cbar_ptype, orientation = 'horizontal', ticks = ptype_ticks, aspect = 35, cax = colorbar_axes)\n",
    "    cbar.ax.set_xticklabels(ptype_labels)\n",
    "    cbar.ax.tick_params(labelsize=20)   \n",
    "    \n",
    "    # Save Individual Figure\n",
    "    fig.savefig(savefiguretitle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "England, John | LU: 20230128"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daes_may21",
   "language": "python",
   "name": "daes_may21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
